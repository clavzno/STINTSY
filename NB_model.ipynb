{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, MaxAbsScaler, Normalizer, OneHotEncoder\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, ParameterGrid\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from scipy.sparse import csr_matrix\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 6: Initial Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the CSV file and take nojte of the shape and info.\n",
    "As we can see, it is a fairly large dataset with 71354 entries and 31 features with the datatypes differing between the types of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Shape: (71210, 30)\n",
      "Dataset Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 71210 entries, 0 to 71209\n",
      "Data columns (total 30 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   PUFREG              71210 non-null  object \n",
      " 1   PUFURB2K10          71210 non-null  object \n",
      " 2   PUFHHSIZE           71210 non-null  int64  \n",
      " 3   PUFC03_REL          71210 non-null  object \n",
      " 4   PUFC04_SEX          71210 non-null  object \n",
      " 5   PUFC05_AGE          71210 non-null  int64  \n",
      " 6   PUFC06_MSTAT        71210 non-null  object \n",
      " 7   PUFC07_GRADE        71210 non-null  object \n",
      " 8   PUFC08_CURSCH       71210 non-null  object \n",
      " 9   PUFC09_GRADTECH     71210 non-null  object \n",
      " 10  PUFC10_CONWR        71210 non-null  object \n",
      " 11  PUFC11_WORK         71210 non-null  object \n",
      " 12  PUFC12_JOB          71210 non-null  object \n",
      " 13  PUFC14_PROCC        71210 non-null  object \n",
      " 14  PUFC16_PKB          71210 non-null  object \n",
      " 15  PUFC17_NATEM        71210 non-null  object \n",
      " 16  PUFC18_PNWHRS       71210 non-null  int64  \n",
      " 17  PUFC19_PHOURS       71210 non-null  int64  \n",
      " 18  PUFC20_PWMORE       71210 non-null  object \n",
      " 19  PUFC21_PLADDW       71210 non-null  object \n",
      " 20  PUFC22_PFWRK        71210 non-null  object \n",
      " 21  PUFC23_PCLASS       71210 non-null  object \n",
      " 22  PUFC24_PBASIS       71210 non-null  object \n",
      " 23  PUFC25_PBASIC       71210 non-null  float64\n",
      " 24  PUFC26_OJOB         71210 non-null  object \n",
      " 25  PUFC28_THOURS       71210 non-null  float64\n",
      " 26  PUFC29_WWM48H       71210 non-null  object \n",
      " 27  PUFC41_WQTR         71210 non-null  object \n",
      " 28  PUFC43_QKB          71210 non-null  object \n",
      " 29  PUFC16_PKB_GENERAL  71210 non-null  object \n",
      "dtypes: float64(2), int64(4), object(24)\n",
      "memory usage: 16.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUFREG</th>\n",
       "      <th>PUFURB2K10</th>\n",
       "      <th>PUFHHSIZE</th>\n",
       "      <th>PUFC03_REL</th>\n",
       "      <th>PUFC04_SEX</th>\n",
       "      <th>PUFC05_AGE</th>\n",
       "      <th>PUFC06_MSTAT</th>\n",
       "      <th>PUFC07_GRADE</th>\n",
       "      <th>PUFC08_CURSCH</th>\n",
       "      <th>PUFC09_GRADTECH</th>\n",
       "      <th>...</th>\n",
       "      <th>PUFC22_PFWRK</th>\n",
       "      <th>PUFC23_PCLASS</th>\n",
       "      <th>PUFC24_PBASIS</th>\n",
       "      <th>PUFC25_PBASIC</th>\n",
       "      <th>PUFC26_OJOB</th>\n",
       "      <th>PUFC28_THOURS</th>\n",
       "      <th>PUFC29_WWM48H</th>\n",
       "      <th>PUFC41_WQTR</th>\n",
       "      <th>PUFC43_QKB</th>\n",
       "      <th>PUFC16_PKB_GENERAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Rural</td>\n",
       "      <td>3</td>\n",
       "      <td>Head</td>\n",
       "      <td>M</td>\n",
       "      <td>49</td>\n",
       "      <td>Married</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>Self Employed</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>Other reasons</td>\n",
       "      <td>yes</td>\n",
       "      <td>Crop and Animal Production, Hunting and Relate...</td>\n",
       "      <td>Agricultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Rural</td>\n",
       "      <td>3</td>\n",
       "      <td>Wife/Spouse</td>\n",
       "      <td>F</td>\n",
       "      <td>61</td>\n",
       "      <td>Married</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>Without Pay (Family Owned Business)</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>no</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>Other reasons</td>\n",
       "      <td>yes</td>\n",
       "      <td>Crop and Animal Production, Hunting and Relate...</td>\n",
       "      <td>Agricultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Rural</td>\n",
       "      <td>3</td>\n",
       "      <td>Son/daughter</td>\n",
       "      <td>M</td>\n",
       "      <td>19</td>\n",
       "      <td>Single</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>Private Establishment</td>\n",
       "      <td>Per Day</td>\n",
       "      <td>5.525453</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>Other reasons</td>\n",
       "      <td>yes</td>\n",
       "      <td>Crop and Animal Production, Hunting and Relate...</td>\n",
       "      <td>Agricultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Rural</td>\n",
       "      <td>4</td>\n",
       "      <td>Head</td>\n",
       "      <td>M</td>\n",
       "      <td>48</td>\n",
       "      <td>Married</td>\n",
       "      <td>Second Year High School</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>Self Employed</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>Other reasons</td>\n",
       "      <td>yes</td>\n",
       "      <td>Crop and Animal Production, Hunting and Relate...</td>\n",
       "      <td>Agricultural</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>Rural</td>\n",
       "      <td>4</td>\n",
       "      <td>Wife/Spouse</td>\n",
       "      <td>F</td>\n",
       "      <td>41</td>\n",
       "      <td>Married</td>\n",
       "      <td>High School Graduate</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>Private Household</td>\n",
       "      <td>Monthly</td>\n",
       "      <td>4.753590</td>\n",
       "      <td>no</td>\n",
       "      <td>4.290459</td>\n",
       "      <td>Requirements of the job</td>\n",
       "      <td>yes</td>\n",
       "      <td>Other Personal Service Activities</td>\n",
       "      <td>Services</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     PUFREG PUFURB2K10  PUFHHSIZE    PUFC03_REL PUFC04_SEX  \\\n",
       "0  Region I - Ilocos Region      Rural          3          Head          M   \n",
       "1  Region I - Ilocos Region      Rural          3   Wife/Spouse          F   \n",
       "2  Region I - Ilocos Region      Rural          3  Son/daughter          M   \n",
       "3  Region I - Ilocos Region      Rural          4          Head          M   \n",
       "4  Region I - Ilocos Region      Rural          4   Wife/Spouse          F   \n",
       "\n",
       "   PUFC05_AGE PUFC06_MSTAT             PUFC07_GRADE PUFC08_CURSCH  \\\n",
       "0          49      Married     High School Graduate            no   \n",
       "1          61      Married     High School Graduate            no   \n",
       "2          19       Single     High School Graduate            no   \n",
       "3          48      Married  Second Year High School            no   \n",
       "4          41      Married     High School Graduate            no   \n",
       "\n",
       "  PUFC09_GRADTECH  ... PUFC22_PFWRK                        PUFC23_PCLASS  \\\n",
       "0              no  ...           no                        Self Employed   \n",
       "1              no  ...           no  Without Pay (Family Owned Business)   \n",
       "2              no  ...           no                Private Establishment   \n",
       "3              no  ...           no                        Self Employed   \n",
       "4              no  ...           no                    Private Household   \n",
       "\n",
       "  PUFC24_PBASIS PUFC25_PBASIC PUFC26_OJOB PUFC28_THOURS  \\\n",
       "0       Monthly      0.000000         yes      3.496508   \n",
       "1       Monthly      0.000000          no      2.197225   \n",
       "2       Per Day      5.525453         yes      3.555348   \n",
       "3       Monthly      0.000000         yes      3.526361   \n",
       "4       Monthly      4.753590          no      4.290459   \n",
       "\n",
       "             PUFC29_WWM48H  PUFC41_WQTR  \\\n",
       "0            Other reasons          yes   \n",
       "1            Other reasons          yes   \n",
       "2            Other reasons          yes   \n",
       "3            Other reasons          yes   \n",
       "4  Requirements of the job          yes   \n",
       "\n",
       "                                          PUFC43_QKB PUFC16_PKB_GENERAL  \n",
       "0  Crop and Animal Production, Hunting and Relate...       Agricultural  \n",
       "1  Crop and Animal Production, Hunting and Relate...       Agricultural  \n",
       "2  Crop and Animal Production, Hunting and Relate...       Agricultural  \n",
       "3  Crop and Animal Production, Hunting and Relate...       Agricultural  \n",
       "4                  Other Personal Service Activities           Services  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df_nb = pd.read_csv('cleaned_df.csv')\n",
    "\n",
    "# Display basic information about the dataset\n",
    "print(\"Dataset Shape:\", df_nb.shape)\n",
    "print(\"Dataset Info:\")\n",
    "df_nb.info()\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df_nb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To first start, we need to preprocess this model to encode the categorical data into numerical data, for this we use a simple label encoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original labels: ['Autonomous Region in Muslim Mindanao' 'Cordillera Administrative Region'\n",
      " 'National Capital Region' 'Region I - Ilocos Region'\n",
      " 'Region II - Cagayan Valley' 'Region III - Central Luzon'\n",
      " 'Region IVA - CALABARZON' 'Region IVB - MIMAROPA'\n",
      " 'Region IX - Zamboanga Peninsula' 'Region V - Bicol'\n",
      " 'Region VI - Western Visayas' 'Region VII - Central Visayas'\n",
      " 'Region VIII - Eastern Visayas' 'Region X - Northern Mindanao'\n",
      " 'Region XI - Davao' 'Region XII - SOCCSKSARGEN' 'Region XIII - Caraga'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Autonomous Region in Muslim Mindanao': 0, 'Cordillera Administrative Region': 1, 'National Capital Region': 2, 'Region I - Ilocos Region': 3, 'Region II - Cagayan Valley': 4, 'Region III - Central Luzon': 5, 'Region IVA - CALABARZON': 6, 'Region IVB - MIMAROPA': 7, 'Region IX - Zamboanga Peninsula': 8, 'Region V - Bicol': 9, 'Region VI - Western Visayas': 10, 'Region VII - Central Visayas': 11, 'Region VIII - Eastern Visayas': 12, 'Region X - Northern Mindanao': 13, 'Region XI - Davao': 14, 'Region XII - SOCCSKSARGEN': 15, 'Region XIII - Caraga': 16}\n",
      "Original labels: ['Rural' 'Urban'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Rural': 0, 'Urban': 1}\n",
      "Original labels: ['Boarder' 'Brothers/sisters' 'Domestic Helper' 'Father/Mother'\n",
      " 'Grandchildren' 'Head' 'Non-Relative' 'Other Relative' 'Son/daughter'\n",
      " 'Son/daughter_law' 'Wife/Spouse'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Boarder': 0, 'Brothers/sisters': 1, 'Domestic Helper': 2, 'Father/Mother': 3, 'Grandchildren': 4, 'Head': 5, 'Non-Relative': 6, 'Other Relative': 7, 'Son/daughter': 8, 'Son/daughter_law': 9, 'Wife/Spouse': 10}\n",
      "Original labels: ['F' 'M'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'F': 0, 'M': 1}\n",
      "Original labels: ['Annuled' 'Divorced/Separate' 'Married' 'Single' 'Unknown' 'Widowed'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Annuled': 0, 'Divorced/Separate': 1, 'Married': 2, 'Single': 3, 'Unknown': 4, 'Widowed': 5}\n",
      "Original labels: ['Agriculture, Forestry, and Fishery Programs'\n",
      " 'Architecture and Building Programs' 'Arts Programs' 'Basic Programs'\n",
      " 'Business and Administration Programs'\n",
      " 'Computing/Information Technology Programs' 'Elementary Graduate'\n",
      " 'Engineering and Engineering Trades Programs'\n",
      " 'Engineering and Engineering trades Programs'\n",
      " 'Environmental Protection Programs' 'First Year College'\n",
      " 'First Year High School/Grade 7' 'First Year Post Secondary'\n",
      " 'Fourth Year College' 'Fourth Year High School' 'Grade 1' 'Grade 2'\n",
      " 'Grade 3' 'Grade 4' 'Grade 5' 'Grade 6' 'Health Programs'\n",
      " 'High School Graduate' 'Humanities Programs'\n",
      " 'Journalism and Information Programs' 'Law Programs'\n",
      " 'Life Sciences Programs' 'Manufacturing and Processing Programs'\n",
      " 'Mathematics and Statistics Programs' 'No Grade Completed'\n",
      " 'Other Programs in Education at the Third Level, First Stage, of the Type that Leads to an Award not Equivalent to a First University or Baccalaureate Degree'\n",
      " 'Other Programs of Education at the Third Level, First Stage, of the Type that Leads to a Baccalaureate or First University/Professional Degree'\n",
      " 'Personal Services Programs' 'Physical Sciences Programs'\n",
      " 'Post Baccalaureate' 'Preschool' 'Second Year College'\n",
      " 'Second Year High School' 'Second Year Post Secondary'\n",
      " 'Security Services Programs' 'Social Services Programs'\n",
      " 'Social and Behavioral Science Programs'\n",
      " 'Teacher Training and Education Sciences Programs' 'Third Year College'\n",
      " 'Third Year High School' 'Transport Services Programs'\n",
      " 'Veterinary Programs'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Agriculture, Forestry, and Fishery Programs': 0, 'Architecture and Building Programs': 1, 'Arts Programs': 2, 'Basic Programs': 3, 'Business and Administration Programs': 4, 'Computing/Information Technology Programs': 5, 'Elementary Graduate': 6, 'Engineering and Engineering Trades Programs': 7, 'Engineering and Engineering trades Programs': 8, 'Environmental Protection Programs': 9, 'First Year College': 10, 'First Year High School/Grade 7': 11, 'First Year Post Secondary': 12, 'Fourth Year College': 13, 'Fourth Year High School': 14, 'Grade 1': 15, 'Grade 2': 16, 'Grade 3': 17, 'Grade 4': 18, 'Grade 5': 19, 'Grade 6': 20, 'Health Programs': 21, 'High School Graduate': 22, 'Humanities Programs': 23, 'Journalism and Information Programs': 24, 'Law Programs': 25, 'Life Sciences Programs': 26, 'Manufacturing and Processing Programs': 27, 'Mathematics and Statistics Programs': 28, 'No Grade Completed': 29, 'Other Programs in Education at the Third Level, First Stage, of the Type that Leads to an Award not Equivalent to a First University or Baccalaureate Degree': 30, 'Other Programs of Education at the Third Level, First Stage, of the Type that Leads to a Baccalaureate or First University/Professional Degree': 31, 'Personal Services Programs': 32, 'Physical Sciences Programs': 33, 'Post Baccalaureate': 34, 'Preschool': 35, 'Second Year College': 36, 'Second Year High School': 37, 'Second Year Post Secondary': 38, 'Security Services Programs': 39, 'Social Services Programs': 40, 'Social and Behavioral Science Programs': 41, 'Teacher Training and Education Sciences Programs': 42, 'Third Year College': 43, 'Third Year High School': 44, 'Transport Services Programs': 45, 'Veterinary Programs': 46}\n",
      "Original labels: ['no' 'yes'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'no': 0, 'yes': 1}\n",
      "Original labels: ['no' 'yes'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'no': 0, 'yes': 1}\n",
      "Original labels: ['Others' 'Students abroad/Tourists'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Others': 0, 'Students abroad/Tourists': 1}\n",
      "Original labels: ['no' 'yes'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'no': 0, 'yes': 1}\n",
      "Original labels: ['no' 'yes'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'no': 0, 'yes': 1}\n",
      "Original labels: ['Armed Forces Occupations' 'Clerical Support Workers'\n",
      " 'Craft and Related Trades Workers' 'Elementary Occupations' 'Managers'\n",
      " 'Plant and Machine Operators and Assemblers' 'Professionals'\n",
      " 'Service and Sales Workers'\n",
      " 'Skilled Agricultural, Forestry and Fishery Workers'\n",
      " 'Technicians and Associate Professionals'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Armed Forces Occupations': 0, 'Clerical Support Workers': 1, 'Craft and Related Trades Workers': 2, 'Elementary Occupations': 3, 'Managers': 4, 'Plant and Machine Operators and Assemblers': 5, 'Professionals': 6, 'Service and Sales Workers': 7, 'Skilled Agricultural, Forestry and Fishery Workers': 8, 'Technicians and Associate Professionals': 9}\n",
      "Original labels: ['Accommodation and Food Service Activities'\n",
      " 'Activities of Extraterritorial Organizations and Bodies'\n",
      " 'Activities of Households as Employers'\n",
      " 'Administrative and Support Service Activities'\n",
      " 'Agriculture and Forestry' 'Arts, Entertainment and Recreation'\n",
      " 'Construction' 'Education'\n",
      " 'Electricity, Gas, Steam and Airconditioning Supply'\n",
      " 'Financial and Insurance Activities' 'Fishing'\n",
      " 'Human Health and Social Work Activities' 'Information and Communication'\n",
      " 'Manufacturing' 'Mining and Quarying' 'Other Service Activities'\n",
      " 'Professional, Scientific and Technical Activities'\n",
      " 'Public Administration and Defense; Compulsory Social Security'\n",
      " 'Real Estate Activities' 'Transportation and Storage'\n",
      " 'Water Supply; Sewage, Waste Management and Remediation Activities'\n",
      " 'Whosale and Retail Trade; Repair of Motor Vehicles and Motorcycles'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Accommodation and Food Service Activities': 0, 'Activities of Extraterritorial Organizations and Bodies': 1, 'Activities of Households as Employers': 2, 'Administrative and Support Service Activities': 3, 'Agriculture and Forestry': 4, 'Arts, Entertainment and Recreation': 5, 'Construction': 6, 'Education': 7, 'Electricity, Gas, Steam and Airconditioning Supply': 8, 'Financial and Insurance Activities': 9, 'Fishing': 10, 'Human Health and Social Work Activities': 11, 'Information and Communication': 12, 'Manufacturing': 13, 'Mining and Quarying': 14, 'Other Service Activities': 15, 'Professional, Scientific and Technical Activities': 16, 'Public Administration and Defense; Compulsory Social Security': 17, 'Real Estate Activities': 18, 'Transportation and Storage': 19, 'Water Supply; Sewage, Waste Management and Remediation Activities': 20, 'Whosale and Retail Trade; Repair of Motor Vehicles and Motorcycles': 21}\n",
      "Original labels: ['Different employer' 'Permanent Job' 'Short-term'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Different employer': 0, 'Permanent Job': 1, 'Short-term': 2}\n",
      "Original labels: ['no' 'yes'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'no': 0, 'yes': 1}\n",
      "Original labels: ['no' 'yes'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'no': 0, 'yes': 1}\n",
      "Original labels: ['no' 'yes'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'no': 0, 'yes': 1}\n",
      "Original labels: ['Employer' \"Gov't/Gov't Corporation\" 'Private Establishment'\n",
      " 'Private Household' 'Self Employed' 'With Pay (Family Owned Business)'\n",
      " 'Without Pay (Family Owned Business)'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Employer': 0, \"Gov't/Gov't Corporation\": 1, 'Private Establishment': 2, 'Private Household': 3, 'Self Employed': 4, 'With Pay (Family Owned Business)': 5, 'Without Pay (Family Owned Business)': 6}\n",
      "Original labels: ['Commission Basis' 'In Kind only' 'Monthly' 'Other Salaries/Wages'\n",
      " 'Pakyaw' 'Per Day' 'Per Hour' 'Per piece'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Commission Basis': 0, 'In Kind only': 1, 'Monthly': 2, 'Other Salaries/Wages': 3, 'Pakyaw': 4, 'Per Day': 5, 'Per Hour': 6, 'Per piece': 7}\n",
      "Original labels: ['no' 'yes'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'no': 0, 'yes': 1}\n",
      "Original labels: ['Ambition, passion for job' 'Exceptional week' 'Other reasons'\n",
      " 'Requirements of the job' 'Wanted more earnings'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Ambition, passion for job': 0, 'Exceptional week': 1, 'Other reasons': 2, 'Requirements of the job': 3, 'Wanted more earnings': 4}\n",
      "Original labels: ['no' 'yes'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'no': 0, 'yes': 1}\n",
      "Original labels: ['Accommodation'\n",
      " 'Activities Auxiliary to Financial Service and Insurance Activities'\n",
      " 'Activities of Extraterritorial Organizations and Bodies'\n",
      " 'Activities of Head Offices; Management Consultancy Activities'\n",
      " 'Activities of Households as Employers of Domestic Personnel'\n",
      " 'Activities of Membership Organizations'\n",
      " 'Advertising and Market Research' 'Air Transport'\n",
      " 'Architecture and Engineering Activities; Technical Testing and Analysis'\n",
      " 'Civil Engineering'\n",
      " 'Computer Programming, Consultancy, and Related Activities'\n",
      " 'Construction of Buildings' 'Creative Arts and Entertainment Activities'\n",
      " 'Crop and Animal Production, Hunting and Related Services Activities'\n",
      " 'Education' 'Electricity, Gas, Steam and Air Conditioning Supply'\n",
      " 'Employment Activities' 'Extraction of Crude Petroleum and Natural Gas'\n",
      " 'Financial Service Activities, Except Insurance and Pension Funding'\n",
      " 'Fishing and Aquaculture' 'Food and Beverage Service Activities'\n",
      " 'Forestry and Logging' 'Gambling and Betting Activities'\n",
      " 'Human Health Activities' 'Information Service Activities'\n",
      " 'Insurance, Reinsurance, and Pension Funding, Except Compulsory Social Security'\n",
      " 'Land Transport and Transport via Pipelines' 'Legal and Accounting'\n",
      " 'Libraries, Archives, Museums and Other Cultural Activities'\n",
      " 'Manufacture of Basic Metals'\n",
      " 'Manufacture of Basic Pharmaceutical Products and Pharmaceutical Preparation'\n",
      " 'Manufacture of Beverages'\n",
      " 'Manufacture of Chemicals and Chemical Products'\n",
      " 'Manufacture of Coke and Refined Petroleum Products'\n",
      " 'Manufacture of Computer, Electronic and Optical Products'\n",
      " 'Manufacture of Electrical Equipment'\n",
      " 'Manufacture of Fabricated Metal Products, Except Machinery and Equipment'\n",
      " 'Manufacture of Food Products' 'Manufacture of Furniture'\n",
      " 'Manufacture of Leather and Related Products'\n",
      " 'Manufacture of Machinery and Equipment, not elsewhere classified'\n",
      " 'Manufacture of Motor Vehicles, Trailers and Semi-Trailers'\n",
      " 'Manufacture of Other NonMetallic Mineral Products'\n",
      " 'Manufacture of Other Transport Equipment'\n",
      " 'Manufacture of Paper and Paper Products'\n",
      " 'Manufacture of Rubber and Plastic Products' 'Manufacture of Textiles'\n",
      " 'Manufacture of Tobacco Products' 'Manufacture of Wearing Apparel'\n",
      " 'Manufacture of Wood and of Products of Wood and Cork, Except Furniture; Manufacture of Articles of Bamboo, Cane, Rattan and the Like; Manufacture of Straw and Plaiting Materials'\n",
      " 'Mining Support Services' 'Mining of Coal and Lignite'\n",
      " 'Mining of Metal Ores'\n",
      " 'Motion Picture, Video and Television Programme Production, Sound Recording and Music Publishing Activities'\n",
      " 'Office Administrative, Office Support and Other Business Activities'\n",
      " 'Other Manufacturing' 'Other Mining and Quarrying'\n",
      " 'Other Personal Service Activities'\n",
      " 'Other Professional, Scientific, and Technical Activities'\n",
      " 'Postal and Courier Activities'\n",
      " 'Printing and Reproduction of Recorded Media'\n",
      " 'Programming and Broadcasting Activities'\n",
      " 'Public Administration and Defense; Compulsory Social Security'\n",
      " 'Publishing Activities' 'Real Estate Activities'\n",
      " 'Remediation Activities and Other Waste Management Services'\n",
      " 'Rental and Leasing Activities'\n",
      " 'Repair and Installation of Machinery and Equipment'\n",
      " 'Repair of Computers and Personal and Household Goods'\n",
      " 'Residential Care Activities'\n",
      " 'Retail Trade, Except of Motor Vehicles and Motorcycles'\n",
      " 'Scientific and Research Development'\n",
      " 'Security and Investigation Activities'\n",
      " 'Services to Buildings and Landscape Activities' 'Sewerage'\n",
      " 'Social Work Activities Without Accommodation'\n",
      " 'Specialized Construction Activities'\n",
      " 'Sports Activities and Amusement and Recreation Activities'\n",
      " 'Telecommunications'\n",
      " 'Travel Agency, Tour Operator, Reservation Service and Related Activities'\n",
      " 'Undifferentiated Goods- and Services-Producing Activities of Private Households for Own Use'\n",
      " 'Veterinary Activities'\n",
      " 'Warehousing and Support Activities for Transportation'\n",
      " 'Waste Collection, Treatment and Disposal Activities; Materials Recovery'\n",
      " 'Water Collection, Treatment and Supply' 'Water Transport'\n",
      " 'Wholesale Trade, Except of Motor Vehicles and Motorcycles'\n",
      " 'Wholesale and Retail Trade and Repair of Motor Vehicles and Motorcycles'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Accommodation': 0, 'Activities Auxiliary to Financial Service and Insurance Activities': 1, 'Activities of Extraterritorial Organizations and Bodies': 2, 'Activities of Head Offices; Management Consultancy Activities': 3, 'Activities of Households as Employers of Domestic Personnel': 4, 'Activities of Membership Organizations': 5, 'Advertising and Market Research': 6, 'Air Transport': 7, 'Architecture and Engineering Activities; Technical Testing and Analysis': 8, 'Civil Engineering': 9, 'Computer Programming, Consultancy, and Related Activities': 10, 'Construction of Buildings': 11, 'Creative Arts and Entertainment Activities': 12, 'Crop and Animal Production, Hunting and Related Services Activities': 13, 'Education': 14, 'Electricity, Gas, Steam and Air Conditioning Supply': 15, 'Employment Activities': 16, 'Extraction of Crude Petroleum and Natural Gas': 17, 'Financial Service Activities, Except Insurance and Pension Funding': 18, 'Fishing and Aquaculture': 19, 'Food and Beverage Service Activities': 20, 'Forestry and Logging': 21, 'Gambling and Betting Activities': 22, 'Human Health Activities': 23, 'Information Service Activities': 24, 'Insurance, Reinsurance, and Pension Funding, Except Compulsory Social Security': 25, 'Land Transport and Transport via Pipelines': 26, 'Legal and Accounting': 27, 'Libraries, Archives, Museums and Other Cultural Activities': 28, 'Manufacture of Basic Metals': 29, 'Manufacture of Basic Pharmaceutical Products and Pharmaceutical Preparation': 30, 'Manufacture of Beverages': 31, 'Manufacture of Chemicals and Chemical Products': 32, 'Manufacture of Coke and Refined Petroleum Products': 33, 'Manufacture of Computer, Electronic and Optical Products': 34, 'Manufacture of Electrical Equipment': 35, 'Manufacture of Fabricated Metal Products, Except Machinery and Equipment': 36, 'Manufacture of Food Products': 37, 'Manufacture of Furniture': 38, 'Manufacture of Leather and Related Products': 39, 'Manufacture of Machinery and Equipment, not elsewhere classified': 40, 'Manufacture of Motor Vehicles, Trailers and Semi-Trailers': 41, 'Manufacture of Other NonMetallic Mineral Products': 42, 'Manufacture of Other Transport Equipment': 43, 'Manufacture of Paper and Paper Products': 44, 'Manufacture of Rubber and Plastic Products': 45, 'Manufacture of Textiles': 46, 'Manufacture of Tobacco Products': 47, 'Manufacture of Wearing Apparel': 48, 'Manufacture of Wood and of Products of Wood and Cork, Except Furniture; Manufacture of Articles of Bamboo, Cane, Rattan and the Like; Manufacture of Straw and Plaiting Materials': 49, 'Mining Support Services': 50, 'Mining of Coal and Lignite': 51, 'Mining of Metal Ores': 52, 'Motion Picture, Video and Television Programme Production, Sound Recording and Music Publishing Activities': 53, 'Office Administrative, Office Support and Other Business Activities': 54, 'Other Manufacturing': 55, 'Other Mining and Quarrying': 56, 'Other Personal Service Activities': 57, 'Other Professional, Scientific, and Technical Activities': 58, 'Postal and Courier Activities': 59, 'Printing and Reproduction of Recorded Media': 60, 'Programming and Broadcasting Activities': 61, 'Public Administration and Defense; Compulsory Social Security': 62, 'Publishing Activities': 63, 'Real Estate Activities': 64, 'Remediation Activities and Other Waste Management Services': 65, 'Rental and Leasing Activities': 66, 'Repair and Installation of Machinery and Equipment': 67, 'Repair of Computers and Personal and Household Goods': 68, 'Residential Care Activities': 69, 'Retail Trade, Except of Motor Vehicles and Motorcycles': 70, 'Scientific and Research Development': 71, 'Security and Investigation Activities': 72, 'Services to Buildings and Landscape Activities': 73, 'Sewerage': 74, 'Social Work Activities Without Accommodation': 75, 'Specialized Construction Activities': 76, 'Sports Activities and Amusement and Recreation Activities': 77, 'Telecommunications': 78, 'Travel Agency, Tour Operator, Reservation Service and Related Activities': 79, 'Undifferentiated Goods- and Services-Producing Activities of Private Households for Own Use': 80, 'Veterinary Activities': 81, 'Warehousing and Support Activities for Transportation': 82, 'Waste Collection, Treatment and Disposal Activities; Materials Recovery': 83, 'Water Collection, Treatment and Supply': 84, 'Water Transport': 85, 'Wholesale Trade, Except of Motor Vehicles and Motorcycles': 86, 'Wholesale and Retail Trade and Repair of Motor Vehicles and Motorcycles': 87}\n",
      "Original labels: ['Agricultural' 'Industrial' 'Services'] \n",
      "\n",
      "Mapping from nominal to numerical labels:\n",
      "{'Agricultural': 0, 'Industrial': 1, 'Services': 2}\n"
     ]
    }
   ],
   "source": [
    "# Encode categorical variables\n",
    "categorical_cols = df_nb.select_dtypes(include=['object']).columns\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_nb[col] = le.fit_transform(df_nb[col])\n",
    "    print(\"Original labels:\", le.classes_, \"\\n\")\n",
    "\n",
    "    print(\"Mapping from nominal to numerical labels:\")\n",
    "    print(dict(zip(le.classes_,le.transform(le.classes_))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see it has all been label encoded into numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUFREG</th>\n",
       "      <th>PUFURB2K10</th>\n",
       "      <th>PUFHHSIZE</th>\n",
       "      <th>PUFC03_REL</th>\n",
       "      <th>PUFC04_SEX</th>\n",
       "      <th>PUFC05_AGE</th>\n",
       "      <th>PUFC06_MSTAT</th>\n",
       "      <th>PUFC07_GRADE</th>\n",
       "      <th>PUFC08_CURSCH</th>\n",
       "      <th>PUFC09_GRADTECH</th>\n",
       "      <th>...</th>\n",
       "      <th>PUFC22_PFWRK</th>\n",
       "      <th>PUFC23_PCLASS</th>\n",
       "      <th>PUFC24_PBASIS</th>\n",
       "      <th>PUFC25_PBASIC</th>\n",
       "      <th>PUFC26_OJOB</th>\n",
       "      <th>PUFC28_THOURS</th>\n",
       "      <th>PUFC29_WWM48H</th>\n",
       "      <th>PUFC41_WQTR</th>\n",
       "      <th>PUFC43_QKB</th>\n",
       "      <th>PUFC16_PKB_GENERAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.496508</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5.525453</td>\n",
       "      <td>1</td>\n",
       "      <td>3.555348</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3.526361</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>4.753590</td>\n",
       "      <td>0</td>\n",
       "      <td>4.290459</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PUFREG  PUFURB2K10  PUFHHSIZE  PUFC03_REL  PUFC04_SEX  PUFC05_AGE  \\\n",
       "0       3           0          3           5           1          49   \n",
       "1       3           0          3          10           0          61   \n",
       "2       3           0          3           8           1          19   \n",
       "3       3           0          4           5           1          48   \n",
       "4       3           0          4          10           0          41   \n",
       "\n",
       "   PUFC06_MSTAT  PUFC07_GRADE  PUFC08_CURSCH  PUFC09_GRADTECH  ...  \\\n",
       "0             2            22              0                0  ...   \n",
       "1             2            22              0                0  ...   \n",
       "2             3            22              0                0  ...   \n",
       "3             2            37              0                0  ...   \n",
       "4             2            22              0                0  ...   \n",
       "\n",
       "   PUFC22_PFWRK  PUFC23_PCLASS  PUFC24_PBASIS  PUFC25_PBASIC  PUFC26_OJOB  \\\n",
       "0             0              4              2       0.000000            1   \n",
       "1             0              6              2       0.000000            0   \n",
       "2             0              2              5       5.525453            1   \n",
       "3             0              4              2       0.000000            1   \n",
       "4             0              3              2       4.753590            0   \n",
       "\n",
       "   PUFC28_THOURS  PUFC29_WWM48H  PUFC41_WQTR  PUFC43_QKB  PUFC16_PKB_GENERAL  \n",
       "0       3.496508              2            1          13                   0  \n",
       "1       2.197225              2            1          13                   0  \n",
       "2       3.555348              2            1          13                   0  \n",
       "3       3.526361              2            1          13                   0  \n",
       "4       4.290459              3            1          57                   2  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we want to be sure to select our target variable and features. We will use the “target” column as our target variable and the rest of the columns as features as type int, due to the fact that we have already encoded the categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_nb.drop(columns=['PUFC14_PROCC'])\n",
    "y = df_nb['PUFC14_PROCC'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first start training a Gaussian NB model for our classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use stratified random sampling for our test set with a test size of 30%, as our dataset is fairly large, this should be sufficient. We also shuffle the data in the process to prevent data leakage when it comes to training and testing the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-27 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-27 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-27 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-27 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-27 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-27 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-27 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-27 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-27 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-27 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-27 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-27 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-27 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-27 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-27 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-27 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-27 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-27 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-27 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-27\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GaussianNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-27\" type=\"checkbox\" checked><label for=\"sk-estimator-id-27\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>GaussianNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.GaussianNB.html\">?<span>Documentation for GaussianNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>GaussianNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 461,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_gnb = GaussianNB()\n",
    "df_gnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure, we print the var_smoothing variable to take note of the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1e-09\n"
     ]
    }
   ],
   "source": [
    "print(df_gnb.var_smoothing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can first use cross validation to create more statistical measures to test the viability of our model. We then train and evaluate it. We use the functions listed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(model, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"Train the model and compute accuracy.\"\"\"\n",
    "    model.fit(X_train, y_train)\n",
    "    train_acc = accuracy_score(y_train, model.predict(X_train))\n",
    "    test_acc = accuracy_score(y_test, model.predict(X_test))\n",
    "    return train_acc, test_acc\n",
    "\n",
    "def compute_cross_val_accuracy(model, X, y, cv=5):\n",
    "    \"\"\"Compute cross-validated accuracy using Stratified K-Fold.\"\"\"\n",
    "    stratified_kfold = StratifiedKFold(n_splits=cv, shuffle=True, random_state=1)\n",
    "    scores = cross_val_score(model, X, y, cv=stratified_kfold, scoring='accuracy')\n",
    "    return scores.mean(), scores.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc, std_acc = compute_cross_val_accuracy(df_gnb, X_train, y_train, cv=5)\n",
    "train_acc, test_acc = train_and_evaluate(df_gnb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.93      0.04        14\n",
      "           1       0.17      0.59      0.26       619\n",
      "           2       0.26      0.71      0.38       861\n",
      "           3       0.85      0.12      0.21      4365\n",
      "           4       0.28      0.40      0.33      1064\n",
      "           5       0.41      0.56      0.48       432\n",
      "           6       0.54      0.59      0.56      2037\n",
      "           7       0.35      0.21      0.26      1904\n",
      "           8       0.62      0.80      0.70      2393\n",
      "           9       0.00      0.00      0.00       553\n",
      "\n",
      "    accuracy                           0.40     14242\n",
      "   macro avg       0.35      0.49      0.32     14242\n",
      "weighted avg       0.55      0.40      0.37     14242\n",
      "\n",
      "mean acc: 0.40176937478477504 std acc: 0.00511020536376734 train acc: 0.4009619435472546 test acc: 0.3997331835416374\n"
     ]
    }
   ],
   "source": [
    "pred_test = df_gnb.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))\n",
    "print(\"mean acc:\", mean_acc, \"std acc:\", std_acc, \"train acc:\", train_acc, \"test acc:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, based on the metrics, our accuracy is extremely low, being under 50%. Given this result, we can test Multinomial NB models instead to see if the results improve/differ such that Naive Bayes may be applicable to our data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multinomial NB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start training and testing our Multinomial NB model the same way we did with our Gaussian NB model, using random stratified sampling and a test set of 30%. We shuffle again to prevent data leakage and/or bias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-28 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-28 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-28 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-28 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-28 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-28 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-28 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-28 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-28 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-28 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-28 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-28 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-28 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-28 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-28 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-28 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-28 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-28 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-28 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-28\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-28\" type=\"checkbox\" checked><label for=\"sk-estimator-id-28\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>MultinomialNB</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.6/modules/generated/sklearn.naive_bayes.MultinomialNB.html\">?<span>Documentation for MultinomialNB</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>MultinomialNB()</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_mnb = MultinomialNB()\n",
    "df_mnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make sure, we print the alpha variable to take note of the default value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "print(df_mnb.alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start computing for cross-validation accuracy, then training and testing our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_acc, std_acc = compute_cross_val_accuracy(df_mnb, X_train, y_train, cv=5)\n",
    "train_acc, test_acc = train_and_evaluate(df_mnb, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.50      0.03        14\n",
      "           1       0.18      0.17      0.18       619\n",
      "           2       0.12      0.06      0.08       861\n",
      "           3       0.47      0.39      0.43      4365\n",
      "           4       0.43      0.44      0.44      1064\n",
      "           5       0.50      0.15      0.23       432\n",
      "           6       0.58      0.46      0.51      2037\n",
      "           7       0.34      0.43      0.38      1904\n",
      "           8       0.57      0.77      0.65      2393\n",
      "           9       0.10      0.12      0.11       553\n",
      "\n",
      "    accuracy                           0.43     14242\n",
      "   macro avg       0.33      0.35      0.30     14242\n",
      "weighted avg       0.43      0.43      0.42     14242\n",
      "\n",
      "mean acc: 0.4273100538855307 std acc: 0.0022302648517894806 train acc: 0.42785423395590505 test acc: 0.42634461452043254\n"
     ]
    }
   ],
   "source": [
    "pred_test = df_mnb.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))\n",
    "print(\"mean acc:\", mean_acc, \"std acc:\", std_acc, \"train acc:\", train_acc, \"test acc:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the accuracy of this model is slightly more accurate than that of the Gaussian NB model we have trained.\n",
    "\n",
    "Although this is the case, the accuracy is still lacking. So we have to check for errors in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 7: Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start with the error analysis to figure out why our models accuracy is so low, we start with the class counts and the class priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   58.  2475.  3442. 17458.  4258.  1727.  8148.  7618.  9572.  2212.]\n",
      "[0.00101812 0.04344544 0.06041988 0.30645275 0.07474372 0.03031526\n",
      " 0.14302766 0.1337242  0.16802415 0.03882882]\n"
     ]
    }
   ],
   "source": [
    "print(df_gnb.class_count_)\n",
    "print(df_gnb.class_prior_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class priors are seemingly imbalanced, with very obvious majority and minority classes which will be more evident given the following metrics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Counts: Counter({3: 21823, 8: 11965, 6: 10185, 7: 9522, 4: 5322, 2: 4303, 1: 3094, 9: 2765, 5: 2159, 0: 72})\n"
     ]
    }
   ],
   "source": [
    "# Count the occurrences of each class\n",
    "class_counts = Counter(y)\n",
    "print(\"Class Counts:\", class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Proportions: {8: 0.16802415391096756, 3: 0.3064597668866732, 7: 0.13371717455413565, 4: 0.0747366942845106, 2: 0.060426906333380145, 6: 0.14302766465384076, 9: 0.03882881617750316, 5: 0.030318775452885832, 1: 0.04344895379862379, 0: 0.0010110939474792867}\n"
     ]
    }
   ],
   "source": [
    "# Calculate the proportion of each class\n",
    "total_samples = len(y)\n",
    "class_proportions = {cls: count / total_samples for cls, count in class_counts.items()}\n",
    "print(\"Class Proportions:\", class_proportions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot class distribution\n",
    "class_counts = pd.Series(y).value_counts()\n",
    "class_counts.plot(kind='bar', color='skyblue')\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the class priors are extremely imbalanced, with majority classes and minority classes in the target variable (y) which in the following blocks of code, will reflect on both the testing and training set evidently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Class Counts:\n",
      " PUFC14_PROCC\n",
      "3    17458\n",
      "8     9572\n",
      "6     8148\n",
      "7     7618\n",
      "4     4258\n",
      "2     3442\n",
      "1     2475\n",
      "9     2212\n",
      "5     1727\n",
      "0       58\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution in training set\n",
    "train_class_counts = pd.Series(y_train).value_counts()\n",
    "print(\"Training Set Class Counts:\\n\", train_class_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Set Class Counts:\n",
      " PUFC14_PROCC\n",
      "3    4365\n",
      "8    2393\n",
      "6    2037\n",
      "7    1904\n",
      "4    1064\n",
      "2     861\n",
      "1     619\n",
      "9     553\n",
      "5     432\n",
      "0      14\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Check class distribution in testing set\n",
    "test_class_counts = pd.Series(y_test).value_counts()\n",
    "print(\"Testing Set Class Counts:\\n\", test_class_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the classes of target variable (y) are imbalanced, we also must check if any other features are highly imbalanced. We use the function listed to check for the top value proportions of these variables using a threshold of 50%, such that if the proportion exceeds the threshold, it will be listed as an imbalanced feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly Imbalanced Features:\n",
      "PUFURB2K10 is highly imbalanced (57.0%)\tImbalance\n",
      "PUFC04_SEX is highly imbalanced (61.6%)\tImbalance\n",
      "PUFC06_MSTAT is highly imbalanced (66.4%)\tImbalance\n",
      "PUFC08_CURSCH is highly imbalanced (97.2%)\tImbalance\n",
      "PUFC09_GRADTECH is highly imbalanced (94.5%)\tImbalance\n",
      "PUFC10_CONWR is highly imbalanced (100.0%)\tImbalance\n",
      "PUFC11_WORK is highly imbalanced (98.5%)\tImbalance\n",
      "PUFC12_JOB is highly imbalanced (98.5%)\tImbalance\n",
      "PUFC17_NATEM is highly imbalanced (75.5%)\tImbalance\n",
      "PUFC20_PWMORE is highly imbalanced (80.4%)\tImbalance\n",
      "PUFC21_PLADDW is highly imbalanced (89.5%)\tImbalance\n",
      "PUFC22_PFWRK is highly imbalanced (97.9%)\tImbalance\n",
      "PUFC24_PBASIS is highly imbalanced (65.9%)\tImbalance\n",
      "PUFC26_OJOB is highly imbalanced (91.7%)\tImbalance\n",
      "PUFC29_WWM48H is highly imbalanced (75.9%)\tImbalance\n",
      "PUFC41_WQTR is highly imbalanced (97.7%)\tImbalance\n",
      "PUFC16_PKB_GENERAL is highly imbalanced (55.5%)\tImbalance\n"
     ]
    }
   ],
   "source": [
    "def find_highly_imbalanced_features(df, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Identify highly imbalanced features in a dataset.\n",
    "    \n",
    "    Parameters:\n",
    "        df (DataFrame): The dataset.\n",
    "        threshold (float): Proportion threshold to consider a feature highly imbalanced.\n",
    "        \n",
    "    Returns:\n",
    "        imbalanced_features (list): List of tuples with feature names and their dominant proportions.\n",
    "    \"\"\"\n",
    "    imbalanced_features = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        # Calculate the proportion of the most frequent value\n",
    "        top_value_proportion = df[col].value_counts(normalize=True).max()\n",
    "        \n",
    "        if top_value_proportion > threshold:\n",
    "            imbalanced_features.append((col, top_value_proportion))\n",
    "    \n",
    "    return imbalanced_features\n",
    "\n",
    "# Example usage\n",
    "imbalanced_features = find_highly_imbalanced_features(df_nb, threshold=0.5)\n",
    "\n",
    "# Print the results\n",
    "print(\"Highly Imbalanced Features:\")\n",
    "for feature, proportion in imbalanced_features:\n",
    "    print(f\"{feature} is highly imbalanced ({proportion:.1%})\\tImbalance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that we now know that we have highly imbalanced variables in our dataset, we may implement methods such as changing the variable smoothing, changing the priors manually, and using SMOTE to synthetically create data to fill the features in uniformly by oversampling the minority class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 8: Improving Model Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the imbalances shown in all the previous section, we may attempt to fix this by adjusting the priors artificially to be uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.00101812 0.04344544 0.06041988 0.30645275 0.07474372 0.03031526\n",
      " 0.14302766 0.1337242  0.16802415 0.03882882]\n"
     ]
    }
   ],
   "source": [
    "print(df_gnb.class_prior_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Adjusted Priors:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.93      0.04        14\n",
      "           1       0.16      0.60      0.25       619\n",
      "           2       0.25      0.68      0.37       861\n",
      "           3       0.86      0.10      0.18      4365\n",
      "           4       0.28      0.47      0.35      1064\n",
      "           5       0.38      0.62      0.47       432\n",
      "           6       0.57      0.55      0.56      2037\n",
      "           7       0.36      0.19      0.25      1904\n",
      "           8       0.63      0.78      0.70      2393\n",
      "           9       0.10      0.00      0.00       553\n",
      "\n",
      "    accuracy                           0.39     14242\n",
      "   macro avg       0.36      0.49      0.32     14242\n",
      "weighted avg       0.56      0.39      0.36     14242\n",
      "\n",
      "mean acc: 0.39150044569893705 std acc: 0.005578869224496578 train acc: 0.39144783036090436 test acc: 0.3884988063474231\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model with adjusted priors\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "adjusted_priors = [1 / len(np.unique(y_train))] * len(np.unique(y_train))  # Uniform priors\n",
    "df_gnb_adjusted = GaussianNB(priors=adjusted_priors)\n",
    "mean_acc_adjusted, std_acc_adjusted = compute_cross_val_accuracy(df_gnb_adjusted, X_train, y_train, cv=5)\n",
    "train_acc_adjusted, test_acc_adjusted = train_and_evaluate(df_gnb_adjusted, X_train, X_test, y_train, y_test)\n",
    "\n",
    "print(\"\\nAdjusted Priors:\")\n",
    "pred_test = df_gnb_adjusted.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))\n",
    "print(\"mean acc:\", mean_acc_adjusted, \"std acc:\", std_acc_adjusted, \"train acc:\", train_acc_adjusted, \"test acc:\", test_acc_adjusted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1 0.1]\n"
     ]
    }
   ],
   "source": [
    "print(df_gnb_adjusted.class_prior_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen, the model that was trained with adjusted priors performed worse than the model with default priors. We can train the model with the application of SMOTE to attempt to fix the class imbalances and compare a model trained with and without SMOTE applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.86      0.04        14\n",
      "           1       0.16      0.53      0.25       619\n",
      "           2       0.25      0.61      0.35       861\n",
      "           3       0.59      0.19      0.28      4365\n",
      "           4       0.27      0.44      0.34      1064\n",
      "           5       0.36      0.56      0.43       432\n",
      "           6       0.60      0.47      0.53      2037\n",
      "           7       0.36      0.24      0.29      1904\n",
      "           8       0.63      0.75      0.69      2393\n",
      "           9       0.13      0.02      0.03       553\n",
      "\n",
      "    accuracy                           0.39     14242\n",
      "   macro avg       0.34      0.47      0.32     14242\n",
      "weighted avg       0.48      0.39      0.39     14242\n",
      "\n",
      "mean acc: 0.3918691963403462 std acc: 0.0026047439556849197 train acc: 0.39237817722230023 test acc: 0.39460749894677716\n"
     ]
    }
   ],
   "source": [
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  # Apply SMOTE\n",
    "    ('classifier', GaussianNB())  # Train Naive Bayes\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "mean_acc_smote, std_acc_smote = compute_cross_val_accuracy(pipeline, X_train, y_train, cv=5)\n",
    "train_acc_smote, test_acc_smote = train_and_evaluate(pipeline, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate the pipeline\n",
    "pred_test = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))\n",
    "print(\"mean acc:\", mean_acc_smote, \"std acc:\", std_acc_smote, \"train acc:\", train_acc_smote, \"test acc:\", test_acc_smote)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the accuracy lowered similarly when we applied SMOTE. From this, we can infer that SMOTE and uniform priors hurt thr models performance more than it does help it, as it skews the true class distribution- making all classes equally likely- which makes it more difficult for NB models to estimate correct probabilities for each class.\n",
    "\n",
    "Given this, we can attempt to remedy class imbalance using sample weights instead. This prevents the priors from being uniform, but it assigns higher weights to minority class samples to balance their influence during the model training while still preserving a proportion of the true class priors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: {0: 98.22068965517241, 1: 2.3017373737373736, 2: 1.6550842533410808, 3: 0.3263145835720014, 4: 1.337905119774542, 5: 3.2986682107701215, 6: 0.6991654393716249, 7: 0.7478078235757417, 8: 0.5951525282072712, 9: 2.5754068716094034}\n"
     ]
    }
   ],
   "source": [
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',  # Automatically balance weights\n",
    "    classes=np.unique(y_train),  # Unique classes in the target\n",
    "    y=y_train  # Target variable\n",
    ")\n",
    "# Convert to a dictionary for easy access\n",
    "class_weights_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}\n",
    "print(\"Class Weights:\", class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign sample weights based on class weights\n",
    "sample_weights = y_train.map(class_weights_dict)\n",
    "\n",
    "# Fit the model with sample weights\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "weighted_gnb = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.93      0.04        14\n",
      "           1       0.17      0.59      0.26       619\n",
      "           2       0.26      0.71      0.38       861\n",
      "           3       0.85      0.12      0.21      4365\n",
      "           4       0.28      0.40      0.33      1064\n",
      "           5       0.41      0.56      0.48       432\n",
      "           6       0.54      0.59      0.56      2037\n",
      "           7       0.35      0.21      0.26      1904\n",
      "           8       0.62      0.80      0.70      2393\n",
      "           9       0.00      0.00      0.00       553\n",
      "\n",
      "    accuracy                           0.40     14242\n",
      "   macro avg       0.35      0.49      0.32     14242\n",
      "weighted avg       0.55      0.40      0.37     14242\n",
      "\n",
      "mean acc: 0.40176937478477504 std acc: 0.00511020536376734 train acc: 0.4009619435472546 test acc: 0.3997331835416374\n"
     ]
    }
   ],
   "source": [
    "mean_acc_weights, std_acc_weights = compute_cross_val_accuracy(weighted_gnb, X_train, y_train, cv=5)\n",
    "train_acc_weights, test_acc_weights = train_and_evaluate(weighted_gnb, X_train, X_test, y_train, y_test)\n",
    "\n",
    "pred_test = weighted_gnb.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))\n",
    "print(\"mean acc:\", mean_acc_weights, \"std acc:\", std_acc_weights, \"train acc:\", train_acc_weights, \"test acc:\", test_acc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, implementing sample weights has lowered the accuracy. This shows us that it is not viable to use any sort of technique that modifies class weights or priors.\n",
    "\n",
    "We can also test MNB with SMOTE and Sample Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.01      0.86      0.02        14\n",
      "           1       0.26      0.23      0.24       619\n",
      "           2       0.14      0.13      0.14       861\n",
      "           3       0.50      0.34      0.40      4365\n",
      "           4       0.38      0.49      0.43      1064\n",
      "           5       0.40      0.34      0.37       432\n",
      "           6       0.65      0.41      0.51      2037\n",
      "           7       0.36      0.36      0.36      1904\n",
      "           8       0.56      0.77      0.65      2393\n",
      "           9       0.08      0.09      0.09       553\n",
      "\n",
      "    accuracy                           0.41     14242\n",
      "   macro avg       0.34      0.40      0.32     14242\n",
      "weighted avg       0.45      0.41      0.42     14242\n",
      "\n",
      "mean acc: 0.41491710594477194 std acc: 0.0015187724038289645 train acc: 0.41467139446706924 test acc: 0.4094930487291111\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('smote', SMOTE(random_state=42)),  # Apply SMOTE to oversample the minority class\n",
    "    ('classifier', MultinomialNB())  # Train Multinomial Naive Bayes\n",
    "])\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "mean_acc_smote, std_acc_smote = compute_cross_val_accuracy(pipeline, X_train, y_train, cv=5)\n",
    "train_acc_smote, test_acc_smote = train_and_evaluate(pipeline, X_train, X_test, y_train, y_test)\n",
    "\n",
    "pred_test = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))\n",
    "print(\"mean acc:\", mean_acc_smote, \"std acc:\", std_acc_smote, \"train acc:\", train_acc_smote, \"test acc:\", test_acc_smote)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.50      0.03        14\n",
      "           1       0.18      0.17      0.18       619\n",
      "           2       0.12      0.06      0.08       861\n",
      "           3       0.47      0.39      0.43      4365\n",
      "           4       0.43      0.44      0.44      1064\n",
      "           5       0.50      0.15      0.23       432\n",
      "           6       0.58      0.46      0.51      2037\n",
      "           7       0.34      0.43      0.38      1904\n",
      "           8       0.57      0.77      0.65      2393\n",
      "           9       0.10      0.12      0.11       553\n",
      "\n",
      "    accuracy                           0.43     14242\n",
      "   macro avg       0.33      0.35      0.30     14242\n",
      "weighted avg       0.43      0.43      0.42     14242\n",
      "\n",
      "mean acc: 0.4273100538855307 std acc: 0.0022302648517894806 train acc: 0.42785423395590505 test acc: 0.42634461452043254\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "# Compute class weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',  # Automatically balance weights\n",
    "    classes=np.unique(y_train),  # Unique classes in the target\n",
    "    y=y_train  # Target variable\n",
    ")\n",
    "\n",
    "# Convert class weights to a dictionary\n",
    "class_weights_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}\n",
    "\n",
    "# Map sample weights based on class weights\n",
    "sample_weights = y_train.map(class_weights_dict)\n",
    "\n",
    "# Train the MultinomialNB model with sample weights\n",
    "weighted_mnb = MultinomialNB(alpha=1.0)\n",
    "\n",
    "mean_acc_weights, std_acc_weights = compute_cross_val_accuracy(weighted_mnb, X_train, y_train, cv=5)\n",
    "train_acc_weights, test_acc_weights = train_and_evaluate(weighted_mnb, X_train, X_test, y_train, y_test)\n",
    "\n",
    "pred_test = weighted_mnb.predict(X_test)\n",
    "print(classification_report(y_test, pred_test))\n",
    "print(\"mean acc:\", mean_acc_weights, \"std acc:\", std_acc_weights, \"train acc:\", train_acc_weights, \"test acc:\", test_acc_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, MNB generally performs better than GNB in this model with the use of SMOTE and sample weights. We can test the different models this time with scalers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB with MaxAbsScaler:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.93      0.04        14\n",
      "           1       0.17      0.59      0.26       619\n",
      "           2       0.25      0.71      0.37       861\n",
      "           3       0.87      0.08      0.15      4365\n",
      "           4       0.28      0.40      0.33      1064\n",
      "           5       0.41      0.56      0.48       432\n",
      "           6       0.54      0.59      0.56      2037\n",
      "           7       0.34      0.22      0.26      1904\n",
      "           8       0.62      0.80      0.70      2393\n",
      "           9       0.00      0.00      0.00       553\n",
      "\n",
      "    accuracy                           0.39     14242\n",
      "   macro avg       0.35      0.49      0.32     14242\n",
      "weighted avg       0.55      0.39      0.35     14242\n",
      "\n",
      "Train Accuracy: 0.3920\n",
      "Test Accuracy: 0.3895\n",
      "\n",
      "MultinomialNB with MaxAbsScaler:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00       619\n",
      "           2       1.00      0.00      0.00       861\n",
      "           3       0.37      0.77      0.50      4365\n",
      "           4       0.36      0.01      0.02      1064\n",
      "           5       0.00      0.00      0.00       432\n",
      "           6       0.45      0.52      0.48      2037\n",
      "           7       0.34      0.10      0.16      1904\n",
      "           8       0.64      0.61      0.62      2393\n",
      "           9       0.00      0.00      0.00       553\n",
      "\n",
      "    accuracy                           0.43     14242\n",
      "   macro avg       0.32      0.20      0.18     14242\n",
      "weighted avg       0.42      0.43      0.35     14242\n",
      "\n",
      "Train Accuracy: 0.4303\n",
      "Test Accuracy: 0.4260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4302766465384075, 0.4259935402331133)"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "# Define pipelines for GNB and MNB with MaxAbsScaler\n",
    "gnb_maxabs_pipeline = Pipeline([\n",
    "    ('scaler', MaxAbsScaler()),  # Apply MaxAbs Scaling\n",
    "    ('classifier', GaussianNB())  # Gaussian Naive Bayes\n",
    "])\n",
    "\n",
    "mnb_maxabs_pipeline = Pipeline([\n",
    "    ('scaler', MaxAbsScaler()),  # Apply MaxAbs Scaling\n",
    "    ('classifier', MultinomialNB())  # Multinomial Naive Bayes\n",
    "])\n",
    "\n",
    "# Function to train and evaluate a pipeline\n",
    "def evaluate_pipeline(pipeline, X_train, X_test, y_train, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    train_acc = pipeline.score(X_train, y_train)\n",
    "    test_acc = pipeline.score(X_test, y_test)\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    return train_acc, test_acc\n",
    "\n",
    "# Evaluate GNB with MaxAbsScaler\n",
    "print(\"GaussianNB with MaxAbsScaler:\")\n",
    "evaluate_pipeline(gnb_maxabs_pipeline, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate MNB with MaxAbsScaler\n",
    "print(\"\\nMultinomialNB with MaxAbsScaler:\")\n",
    "evaluate_pipeline(mnb_maxabs_pipeline, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB with Normalizer:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.02      0.93      0.05        14\n",
      "           1       0.17      0.46      0.25       619\n",
      "           2       0.31      0.53      0.39       861\n",
      "           3       0.74      0.23      0.36      4365\n",
      "           4       0.31      0.47      0.38      1064\n",
      "           5       0.43      0.60      0.50       432\n",
      "           6       0.44      0.66      0.53      2037\n",
      "           7       0.29      0.17      0.22      1904\n",
      "           8       0.66      0.77      0.71      2393\n",
      "           9       0.00      0.00      0.00       553\n",
      "\n",
      "    accuracy                           0.42     14242\n",
      "   macro avg       0.34      0.48      0.34     14242\n",
      "weighted avg       0.50      0.42      0.41     14242\n",
      "\n",
      "Train Accuracy: 0.4271\n",
      "Test Accuracy: 0.4244\n",
      "\n",
      "MultinomialNB with Normalizer:\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        14\n",
      "           1       0.00      0.00      0.00       619\n",
      "           2       0.00      0.00      0.00       861\n",
      "           3       0.31      1.00      0.47      4365\n",
      "           4       0.00      0.00      0.00      1064\n",
      "           5       0.00      0.00      0.00       432\n",
      "           6       0.00      0.00      0.00      2037\n",
      "           7       0.00      0.00      0.00      1904\n",
      "           8       0.00      0.00      0.00      2393\n",
      "           9       0.00      0.00      0.00       553\n",
      "\n",
      "    accuracy                           0.31     14242\n",
      "   macro avg       0.03      0.10      0.05     14242\n",
      "weighted avg       0.09      0.31      0.14     14242\n",
      "\n",
      "Train Accuracy: 0.3065\n",
      "Test Accuracy: 0.3065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.3064527454009268, 0.30648785282965874)"
      ]
     },
     "execution_count": 451,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "# Define pipelines for GNB and MNB with MaxAbsScaler\n",
    "gnb_norm_pipeline = Pipeline([\n",
    "    ('scaler', Normalizer()),  # Apply Normalizer Scaling\n",
    "    ('classifier', GaussianNB())  # Gaussian Naive Bayes\n",
    "])\n",
    "\n",
    "mnb_norm_pipeline = Pipeline([\n",
    "    ('scaler', Normalizer()),  # Apply Normalizer Scaling\n",
    "    ('classifier', MultinomialNB())  # Multinomial Naive Bayes\n",
    "])\n",
    "\n",
    "# Function to train and evaluate a pipeline\n",
    "def evaluate_pipeline(pipeline, X_train, X_test, y_train, y_test):\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    train_acc = pipeline.score(X_train, y_train)\n",
    "    test_acc = pipeline.score(X_test, y_test)\n",
    "    print(f\"Train Accuracy: {train_acc:.4f}\")\n",
    "    print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "    return train_acc, test_acc\n",
    "\n",
    "# Evaluate GNB with Normalizer\n",
    "print(\"GaussianNB with Normalizer:\")\n",
    "evaluate_pipeline(gnb_norm_pipeline, X_train, X_test, y_train, y_test)\n",
    "\n",
    "# Evaluate MNB with Normalizer\n",
    "print(\"\\nMultinomialNB with Normalizer:\")\n",
    "evaluate_pipeline(mnb_norm_pipeline, X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can experiment even further by changing the different hyperparameters of algorithms such as select-K-best feature selection, different scalers, alphas, and var_smoothing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing different optimizations\n",
    "\n",
    "Instead of making the priors uniform or doing something about the distribution of classes, we may instead try using feature selection in hopes of improving the accuracy of the model.\n",
    "\n",
    "We test different K values for select-K-best feature selection, alpha values for Multinomial NB models, and different scalers (MaxAbsScaler, and Normalizer), and var_smoothing values for GaussianNB\n",
    "\n",
    "We can also test models with different parameter grids:\n",
    "* For Multinomial NB, we define different alpha values [default = 1.0], and whether fit_prior (whether the model assumes uniform class priors, or calculates prior probabilities based on the original distribution of classes in the training data) is true or false.\n",
    "* For Gaussian NB, we define var_smoothing [default = 1e-09] small values to add to the variance of each feature during the calculation of probabilities to help numerical stability with instances wherein the model has to work with divisions with zeros or numbers extremely close to zero.\n",
    "\n",
    "We test the model using different scalers, namely MaxAbsScaler and Normalizer.\n",
    "* MaxAbsScaler scales each feature by dividing it by the maximum absolute value of said feature. This will ensure that all feature variables are in range [-1, 1] while also preserving sparsity. It does nolt shift the data, making it more suitable for sparse and larger data sets (which is applicable to our dataset).\n",
    "* Normalizer scales each row individually to have a unit norm (L1 or L2 norm), such that the sum of all absolute values or square root of the sum of squares of feature values will equal to 1. We use this as Gaussian NB models are assumed to work better when features are normalized to a consistent scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df_nb.drop(columns=['PUFC14_PROCC'])\n",
    "y = df_nb['PUFC14_PROCC'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the functions listed to apply our scaling methods and feature selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_feature_selection(X_train, X_test, y_train, k):\n",
    "    \"\"\"Apply SelectKBest feature selection.\"\"\"\n",
    "    selector = SelectKBest(mutual_info_classif, k=k)\n",
    "    X_train_k = selector.fit_transform(X_train, y_train)\n",
    "    X_test_k = selector.transform(X_test)\n",
    "    return X_train_k, X_test_k\n",
    "\n",
    "def apply_scaling(scaler, X_train, X_test):\n",
    "    \"\"\"Apply scaling (MaxAbsScaler, or Normalizer).\"\"\"\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    return X_train_scaled, X_test_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start evaluating the different models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[454]\u001b[39m\u001b[32m, line 28\u001b[39m\n\u001b[32m     25\u001b[39m X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=\u001b[32m0.2\u001b[39m, random_state=\u001b[32m1\u001b[39m, stratify=y)\n\u001b[32m     27\u001b[39m \u001b[38;5;66;03m# Apply feature selection\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m X_train_k, X_test_k = \u001b[43mapply_feature_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# Apply the scaler\u001b[39;00m\n\u001b[32m     31\u001b[39m X_train_k = scaler.fit_transform(X_train_k)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[453]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mapply_feature_selection\u001b[39m\u001b[34m(X_train, X_test, y_train, k)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Apply SelectKBest feature selection.\"\"\"\u001b[39;00m\n\u001b[32m      3\u001b[39m selector = SelectKBest(mutual_info_classif, k=k)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m X_train_k = \u001b[43mselector\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m X_test_k = selector.transform(X_test)\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X_train_k, X_test_k\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:921\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, **fit_params).transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:569\u001b[39m, in \u001b[36m_BaseFilter.fit\u001b[39m\u001b[34m(self, X, y)\u001b[39m\n\u001b[32m    564\u001b[39m     X, y = validate_data(\n\u001b[32m    565\u001b[39m         \u001b[38;5;28mself\u001b[39m, X, y, accept_sparse=[\u001b[33m\"\u001b[39m\u001b[33mcsr\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcsc\u001b[39m\u001b[33m\"\u001b[39m], multi_output=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    566\u001b[39m     )\n\u001b[32m    568\u001b[39m \u001b[38;5;28mself\u001b[39m._check_params(X, y)\n\u001b[32m--> \u001b[39m\u001b[32m569\u001b[39m score_func_ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mscore_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    570\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(score_func_ret, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    571\u001b[39m     \u001b[38;5;28mself\u001b[39m.scores_, \u001b[38;5;28mself\u001b[39m.pvalues_ = score_func_ret\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_param_validation.py:189\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m func_sig = signature(func)\n\u001b[32m    193\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:571\u001b[39m, in \u001b[36mmutual_info_classif\u001b[39m\u001b[34m(X, y, discrete_features, n_neighbors, copy, random_state, n_jobs)\u001b[39m\n\u001b[32m    475\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Estimate mutual information for a discrete target variable.\u001b[39;00m\n\u001b[32m    476\u001b[39m \n\u001b[32m    477\u001b[39m \u001b[33;03mMutual information (MI) [1]_ between two random variables is a non-negative\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    568\u001b[39m \u001b[33;03m       0.     , 0.     , 0.     , 0.      , 0.        ])\u001b[39;00m\n\u001b[32m    569\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    570\u001b[39m check_classification_targets(y)\n\u001b[32m--> \u001b[39m\u001b[32m571\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_estimate_mi\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    572\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    573\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    574\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiscrete_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    575\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdiscrete_target\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    576\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    577\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    578\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    579\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    580\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:317\u001b[39m, in \u001b[36m_estimate_mi\u001b[39m\u001b[34m(X, y, discrete_features, discrete_target, n_neighbors, copy, random_state, n_jobs)\u001b[39m\n\u001b[32m    310\u001b[39m     y = scale(y, with_mean=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    311\u001b[39m     y += (\n\u001b[32m    312\u001b[39m         \u001b[32m1e-10\u001b[39m\n\u001b[32m    313\u001b[39m         * np.maximum(\u001b[32m1\u001b[39m, np.mean(np.abs(y)))\n\u001b[32m    314\u001b[39m         * rng.standard_normal(size=n_samples)\n\u001b[32m    315\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m mi = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_compute_mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_feature\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_feature\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_iterate_columns\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscrete_mask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.array(mi)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:167\u001b[39m, in \u001b[36m_compute_mi\u001b[39m\u001b[34m(x, y, x_discrete, y_discrete, n_neighbors)\u001b[39m\n\u001b[32m    165\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _compute_mi_cd(y, x, n_neighbors)\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m x_discrete \u001b[38;5;129;01mand\u001b[39;00m y_discrete:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_compute_mi_cd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    169\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _compute_mi_cc(x, y, n_neighbors)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_mutual_info.py:129\u001b[39m, in \u001b[36m_compute_mi_cd\u001b[39m\u001b[34m(c, d, n_neighbors)\u001b[39m\n\u001b[32m    127\u001b[39m nn.set_params(n_neighbors=k)\n\u001b[32m    128\u001b[39m nn.fit(c[mask])\n\u001b[32m--> \u001b[39m\u001b[32m129\u001b[39m r = \u001b[43mnn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkneighbors\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m    130\u001b[39m radius[mask] = np.nextafter(r[:, -\u001b[32m1\u001b[39m], \u001b[32m0\u001b[39m)\n\u001b[32m    131\u001b[39m k_all[mask] = k\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\neighbors\\_base.py:923\u001b[39m, in \u001b[36mKNeighborsMixin.kneighbors\u001b[39m\u001b[34m(self, X, n_neighbors, return_distance)\u001b[39m\n\u001b[32m    918\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m issparse(X):\n\u001b[32m    919\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    920\u001b[39m             \u001b[33m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m does not work with sparse matrices. Densify the data, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    921\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor set algorithm=\u001b[39m\u001b[33m'\u001b[39m\u001b[33mbrute\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m % \u001b[38;5;28mself\u001b[39m._fit_method\n\u001b[32m    922\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m923\u001b[39m     chunked_results = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mthreads\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tree\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43ms\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturn_distance\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgen_even_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    928\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33minternal: _fit_method not recognized\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msklearn\\\\neighbors\\\\_binary_tree.pxi:1191\u001b[39m, in \u001b[36msklearn.neighbors._kd_tree.BinaryTree64.query\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32msklearn\\\\neighbors\\\\_binary_tree.pxi:524\u001b[39m, in \u001b[36msklearn.neighbors._kd_tree.NeighborsHeap64.__init__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Marcus\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\numpy\\core\\numeric.py:330\u001b[39m, in \u001b[36mfull\u001b[39m\u001b[34m(shape, fill_value, dtype, order, like)\u001b[39m\n\u001b[32m    328\u001b[39m     dtype = fill_value.dtype\n\u001b[32m    329\u001b[39m a = empty(shape, dtype, order)\n\u001b[32m--> \u001b[39m\u001b[32m330\u001b[39m \u001b[43mmultiarray\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcopyto\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43munsafe\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Initialize results dictionary\n",
    "results = []\n",
    "\n",
    "# Define configurations\n",
    "scalers = {\n",
    "    \"Max-Abs Scaling\": MaxAbsScaler(),\n",
    "    \"Normalizer\": Normalizer()\n",
    "}\n",
    "models = {\n",
    "    \"Gaussian NB\": GaussianNB(),\n",
    "    \"Multinomial NB\": MultinomialNB(),\n",
    "}\n",
    "# Define parameter grids for each model (ParameterGrid)\n",
    "param_grids = {\n",
    "    \"Multinomial NB\": {\"alpha\": [0.1, 0.5, 1.0, 1.5, 2.0], \"fit_prior\": [True, False]},\n",
    "    \"Gaussian NB\": {\"var_smoothing\": [1e-09, 1e-08, 1e-07, 1e-06, 1e-05]}  # Parameter grid for GaussianNB\n",
    "}\n",
    "\n",
    "k_values = range(1, X_train.shape[1] + 1)  # Range of K for feature selection\n",
    "\n",
    "# Loop through configurations\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    for k in k_values:\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "        # Apply feature selection\n",
    "        X_train_k, X_test_k = apply_feature_selection(X_train, X_test, y_train, k)\n",
    "\n",
    "        # Apply the scaler\n",
    "        X_train_k = scaler.fit_transform(X_train_k)\n",
    "        X_test_k = scaler.transform(X_test_k)\n",
    "\n",
    "        # Convert to sparse matrices if needed\n",
    "        X_train_k = csr_matrix(X_train_k)\n",
    "        X_test_k = csr_matrix(X_test_k)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            if model_name == \"Multinomial NB\":\n",
    "                # Multinomial NB models with different alpha values or parameter grids\n",
    "                param_grid = param_grids[model_name]\n",
    "                for params in ParameterGrid(param_grid):\n",
    "                    model.set_params(**params)\n",
    "\n",
    "                    # Compute cross-validation metrics\n",
    "                    mean_acc, std_acc = compute_cross_val_accuracy(model, X_train_k, y_train, cv=5)\n",
    "\n",
    "                    # Compute train and test accuracy\n",
    "                    train_acc, test_acc = train_and_evaluate(model, X_train_k, X_test_k, y_train, y_test)\n",
    "\n",
    "                    results.append({\n",
    "                        \"Model\": f\"{model_name} + Select-K-Best (K={k}) + Params={params} + Scaler={scaler_name}\",\n",
    "                        \"Mean CV Accuracy\": mean_acc,\n",
    "                        \"Std CV Accuracy\": std_acc,\n",
    "                        \"Train Accuracy\": train_acc,\n",
    "                        \"Test Accuracy\": test_acc\n",
    "                    })\n",
    "\n",
    "            else:\n",
    "                # Gaussian NB with ParameterGrid\n",
    "                param_grid = param_grids[model_name]\n",
    "                for params in ParameterGrid(param_grid):\n",
    "                    model.set_params(**params)\n",
    "\n",
    "                    # Compute cross-validation metrics\n",
    "                    mean_acc, std_acc = compute_cross_val_accuracy(model, X_train_k.toarray(), y_train, cv=5)\n",
    "\n",
    "                    # Compute train and test accuracy\n",
    "                    train_acc, test_acc = train_and_evaluate(model, X_train_k.toarray(), X_test_k.toarray(), y_train, y_test)\n",
    "\n",
    "                    results.append({\n",
    "                        \"Model\": f\"{model_name} + Select-K-Best (K={k}) + Params={params} + Scaler={scaler_name}\",\n",
    "                        \"Mean CV Accuracy\": mean_acc,\n",
    "                        \"Std CV Accuracy\": std_acc,\n",
    "                        \"Train Accuracy\": train_acc,\n",
    "                        \"Test Accuracy\": test_acc\n",
    "                    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "print(results_df)\n",
    "\n",
    "# Find the best model based on Mean CV Accuracy\n",
    "best_model = results_df.loc[results_df['Mean CV Accuracy'].idxmax()]\n",
    "print(f\"\\nBest Model using Label Encoder: {best_model['Model']}\")\n",
    "print(f\"Mean CV Accuracy: {best_model['Mean CV Accuracy']}\")\n",
    "print(f\"Std CV Accuracy: {best_model['Std CV Accuracy']}\")\n",
    "print(f\"Train Accuracy: {best_model['Train Accuracy']}\")\n",
    "print(f\"Test Accuracy: {best_model['Test Accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our best model is using Gaussian NB using a Normalizer Scaler, with a K value of 17 for select-K-best feature selection, and a var_smoothing of 1e-06\n",
    "\n",
    "We have only experimented so far on the model using a Label Encoder to convert the nominal labels into numerical ones.\n",
    "\n",
    "We can test the models again, with the same iterative method but this time using one-hot-encoding to convert the nominal labels into numerical ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df_nb_ohe = pd.read_csv('cleaned_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables using OneHotEncoder\n",
    "categorical_cols = df_nb.select_dtypes(include=['object']).columns\n",
    "one_hot_encoder = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "# Apply one-hot encoding\n",
    "df_one_hot = pd.DataFrame(one_hot_encoder.fit_transform(df_nb_ohe[categorical_cols]),\n",
    "                          columns=one_hot_encoder.get_feature_names_out(categorical_cols))\n",
    "\n",
    "# Drop original categorical columns and concatenate one-hot encoded columns\n",
    "df_nb_ohe = df_nb_ohe.drop(columns=categorical_cols).reset_index(drop=True)\n",
    "df_nb_ohe = pd.concat([df_nb, df_one_hot], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and target variable\n",
    "X = df_nb_ohe.drop(columns=['PUFC14_PROCC'])  \n",
    "y = df_nb_ohe['PUFC14_PROCC'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Model  Mean CV Accuracy  \\\n",
      "0    Gaussian NB + Select-K-Best (K=1) + Params={'v...          0.345246   \n",
      "1    Gaussian NB + Select-K-Best (K=1) + Params={'v...          0.345246   \n",
      "2    Gaussian NB + Select-K-Best (K=1) + Params={'v...          0.345246   \n",
      "3    Gaussian NB + Select-K-Best (K=1) + Params={'v...          0.345246   \n",
      "4    Gaussian NB + Select-K-Best (K=1) + Params={'v...          0.345246   \n",
      "..                                                 ...               ...   \n",
      "865  Multinomial NB + Select-K-Best (K=29) + Params...          0.404385   \n",
      "866  Multinomial NB + Select-K-Best (K=29) + Params...          0.306453   \n",
      "867  Multinomial NB + Select-K-Best (K=29) + Params...          0.404420   \n",
      "868  Multinomial NB + Select-K-Best (K=29) + Params...          0.306453   \n",
      "869  Multinomial NB + Select-K-Best (K=29) + Params...          0.403964   \n",
      "\n",
      "     Std CV Accuracy  Train Accuracy  Test Accuracy  \n",
      "0           0.003741        0.346739       0.343421  \n",
      "1           0.003741        0.346739       0.343421  \n",
      "2           0.003741        0.346739       0.343421  \n",
      "3           0.003741        0.346739       0.343421  \n",
      "4           0.003741        0.346739       0.343421  \n",
      "..               ...             ...            ...  \n",
      "865         0.002871        0.405491       0.404648  \n",
      "866         0.000053        0.306453       0.306488  \n",
      "867         0.002573        0.405385       0.405140  \n",
      "868         0.000053        0.306453       0.306488  \n",
      "869         0.002894        0.405403       0.404508  \n",
      "\n",
      "[870 rows x 5 columns]\n",
      "\n",
      "Best Model using Label Encoder: Gaussian NB + Select-K-Best (K=17) + Params={'var_smoothing': 1e-07} + Scaler=Normalizer\n",
      "Mean CV Accuracy: 0.4933120446746299\n",
      "Std CV Accuracy: 0.003459321833985575\n",
      "Train Accuracy: 0.49355778682769275\n",
      "Test Accuracy: 0.48904648223564107\n"
     ]
    }
   ],
   "source": [
    "# Initialize results dictionary\n",
    "results = []\n",
    "\n",
    "# Define configurations\n",
    "scalers = {\n",
    "    \"Max-Abs Scaling\": MaxAbsScaler(),\n",
    "    \"Normalizer\": Normalizer()\n",
    "}\n",
    "models = {\n",
    "    \"Gaussian NB\": GaussianNB(),\n",
    "    \"Multinomial NB\": MultinomialNB(),\n",
    "}\n",
    "# Define parameter grids for each model (ParameterGrid)\n",
    "param_grids = {\n",
    "    \"Multinomial NB\": {\"alpha\": [0.1, 0.5, 1.0, 1.5, 2.0], \"fit_prior\": [True, False]},\n",
    "    \"Gaussian NB\": {\"var_smoothing\": [1e-09, 1e-08, 1e-07, 1e-06, 1e-05]}  # Parameter grid for GaussianNB\n",
    "}\n",
    "\n",
    "k_values = range(1, X_train.shape[1] + 1)  # Range of K for feature selection\n",
    "\n",
    "# Loop through configurations\n",
    "for scaler_name, scaler in scalers.items():\n",
    "    for k in k_values:\n",
    "        # Split the dataset into training and testing sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n",
    "\n",
    "        # Apply feature selection\n",
    "        X_train_k, X_test_k = apply_feature_selection(X_train, X_test, y_train, k)\n",
    "\n",
    "        # Apply the scaler\n",
    "        X_train_k = scaler.fit_transform(X_train_k)\n",
    "        X_test_k = scaler.transform(X_test_k)\n",
    "\n",
    "        # Convert to sparse matrices if needed\n",
    "        X_train_k = csr_matrix(X_train_k)\n",
    "        X_test_k = csr_matrix(X_test_k)\n",
    "\n",
    "        for model_name, model in models.items():\n",
    "            if model_name == \"Multinomial NB\":\n",
    "                # Multinomial NB models with different alpha values or parameter grids\n",
    "                param_grid = param_grids[model_name]\n",
    "                for params in ParameterGrid(param_grid):\n",
    "                    model.set_params(**params)\n",
    "\n",
    "                    # Compute cross-validation metrics\n",
    "                    mean_acc, std_acc = compute_cross_val_accuracy(model, X_train_k, y_train, cv=5)\n",
    "\n",
    "                    # Compute train and test accuracy\n",
    "                    train_acc, test_acc = train_and_evaluate(model, X_train_k, X_test_k, y_train, y_test)\n",
    "\n",
    "                    results.append({\n",
    "                        \"Model\": f\"{model_name} + Select-K-Best (K={k}) + Params={params} + Scaler={scaler_name}\",\n",
    "                        \"Mean CV Accuracy\": mean_acc,\n",
    "                        \"Std CV Accuracy\": std_acc,\n",
    "                        \"Train Accuracy\": train_acc,\n",
    "                        \"Test Accuracy\": test_acc\n",
    "                    })\n",
    "\n",
    "            else:\n",
    "                # Gaussian NB with ParameterGrid\n",
    "                param_grid = param_grids[model_name]\n",
    "                for params in ParameterGrid(param_grid):\n",
    "                    model.set_params(**params)\n",
    "\n",
    "                    # Compute cross-validation metrics\n",
    "                    mean_acc, std_acc = compute_cross_val_accuracy(model, X_train_k.toarray(), y_train, cv=5)\n",
    "\n",
    "                    # Compute train and test accuracy\n",
    "                    train_acc, test_acc = train_and_evaluate(model, X_train_k.toarray(), X_test_k.toarray(), y_train, y_test)\n",
    "\n",
    "                    results.append({\n",
    "                        \"Model\": f\"{model_name} + Select-K-Best (K={k}) + Params={params} + Scaler={scaler_name}\",\n",
    "                        \"Mean CV Accuracy\": mean_acc,\n",
    "                        \"Std CV Accuracy\": std_acc,\n",
    "                        \"Train Accuracy\": train_acc,\n",
    "                        \"Test Accuracy\": test_acc\n",
    "                    })\n",
    "\n",
    "# Convert results to DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Display results\n",
    "print(results_df)\n",
    "\n",
    "# Find the best model based on Mean CV Accuracy\n",
    "best_model = results_df.loc[results_df['Mean CV Accuracy'].idxmax()]\n",
    "print(f\"\\nBest Model using Label Encoder: {best_model['Model']}\")\n",
    "print(f\"Mean CV Accuracy: {best_model['Mean CV Accuracy']}\")\n",
    "print(f\"Std CV Accuracy: {best_model['Std CV Accuracy']}\")\n",
    "print(f\"Train Accuracy: {best_model['Train Accuracy']}\")\n",
    "print(f\"Test Accuracy: {best_model['Test Accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, despite using a different encoding method, the results still seem to be similar to that of label encoded models.\n",
    "The best model parameters for one hot encoded models have also not differed from that of the label encoded models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "models = [\"GNB\", \"MNB\", \"GNB + ADJUSTED PRIORS\", \"GNB + SMOTE\", \"GNB + SAMPLE WEIGHTS\", \n",
    "          \"MNB + SMOTE\", \"MNB + SAMPLE WEIGHTS\", \"Best Model (Label Encoder)\", \"Best Model (One-Hot Encoder)\"]\n",
    "\n",
    "accuracies = [0.4064, 0.4273, 0.3885, 0.3965, 0.4010, 0.4147, 0.4279, 0.4890, 0.4890]\n",
    "\n",
    "# Plot Accuracy\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.bar(models, accuracies, color='skyblue')\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.title(\"Model Accuracy Comparison\")\n",
    "plt.ylim(0.38, 0.5)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
